---
title: "PEP2"
author: "Sebastián Cassone & Nicolás Salinas"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Pregunta 1

Librerias requeridas
```{r}
library(WRS2)
library(boot)
library(simpleboot)
library(ggpubr)
library(bootES)
```

Ya que el profesor Oak desea evaluar su nueva estrategia de entrenamiento Pokémon, ha aumentado la velocidad de ataque  de sus Pokémon en más de 1 punto. Para esto, se ha recolectado una muestra aleatoria de 10 Pokémon de entre más de 600.

Para realizar este análisis se solicitará utilizar bootstrapping. Primeramente, se deben cargar los datos a utilizar; por lo tanto, se creará el DataFrame.


```{r}
#Se crea el data.frame
pokemon <- data.frame(
  pokemon = c("pikachu", "charmander", "bulbasaur", "squirtle", "Lapras", "Gengar", "Kadabra", "Magikarp", "Snorlax", "kabutops"),
  Antes = c(16.16, 12.29, 14.45, 9.60, 12.95, 9.37, 19.61, 7.24, 11.81, 13.96),
  Despues = c(11.38, 6.26, 7.64, 8.92, 16.10, 9.54, 14.72, 12.02, 15.49, 17.68)
)

```
Una vez cargados los datos, se procederá a realizar la hipótesis nula y la hipótesis alternativa:

Ho: La velocidad de ataque de los Pokémon no ha cambiado después de la nueva estrategia de entrenamiento: u = ub
Ha: La velocidad de ataque de los Pokémon ha aumentado más de un punto después del entrenamiento: u > ub

Al analizar las muestras, podemos darnos cuenta de que son muestras dependientes, ya que una corresponde a la velocidad de ataque antes del entrenamiento y la otra a la velocidad de ataque después del entrenamiento de los mismos Pokémon. Debido a que siempre son los mismos Pokémon, se puede apreciar que son muestras dependientes.

Por lo tanto, debemos utilizar bootstrapping para muestras pareadas. Primero, se deben restar los valores de "Antes" y "Después" para obtener la diferencia en la velocidad de ataque de cada Pokémon, y a esta diferencia se le aplicará bootstrapping.

Cabe señalar que el estadístico a utilizar será la diferencia en la velocidad de ataque de los Pokémon, ya que este es el valor que se desea evaluar para determinar si ha cambiado o no después del entrenamiento.

```{r}
#Se restan los valores de "Antes" y "Despues" para obtener la diferencia de velocidad de ataque de cada pokemon
pokemon_diferencia <- pokemon$Antes - pokemon$Despues

```

Una vez que tengamos la diferencia entre las velocidades de ataque, podemos proceder a definir los valores para realizar bootstrapping.

```{r}
confianza = 0.99
repeticiones = 100
```
Una vez definidos los datos, que, como se puede apreciar, son el nivel de confianza solicitado, el cual es del 99%, y la cantidad de repeticiones, que es de 100, se puede proceder a realizar bootstrapping.

```{r}
# se define la semilla
set.seed(1234)
#Se realiza el bootstraping


bootstrap_result <- bootES(pokemon_diferencia, R = repeticiones, ci.type = "bca", ci.conf =confianza, plot = TRUE )

print(bootstrap_result)


```
Como se puede apreciar en los resultados obtenidos, se obtiene un CI(low) de -2.154 y un CI(high) de 5.229. Sabemos que CI hace referencia a los límites inferior y superior del intervalo de confianza. Se puede observar que el intervalo de confianza es de -2.154 a 5.229. Este intervalo incluye valores menores a 1, lo que sugiere que, aunque el entrenamiento pueda hacer que la velocidad de ataque aumente en más de 1 punto, también puede aumentar en menos de 1 punto e incluso disminuir en algunos casos.

En conclusión, no existe evidencia suficiente para rechazar la hipótesis nula en favor de la hipótesis alternativa sobre el aumento en 1 punto de la velocidad de ataque de los Pokémon del profesor Oak.

## Pregunta 2
Se importan las librerías necesarias para el desarrollo del ejercicio.
```{r, echo = FALSE}
library(car)
library(caret)
library(dplyr)
library(ggpubr)
library(leaps)
library(pROC)
library(psych)
library(gridExtra)
```


Comenzamos a leer el archivo del éxito académico.
```{r}
src_dir <- "/home/seba/Documentos/ejercicios_R/EI/estadistica-pep-2"
src_basename <- "EI-2024-1-PE2-Datos-forma3.csv"
src_file <- file.path(src_dir, src_basename)
datos <- read.csv2(file = src_file, stringsAsFactors = TRUE)
```

Luego, obtenemos el conjunto de entrenamiento y de prueba.

```{r}
set.seed(2128)
muestra_a <- datos |> filter(estado == "R") |>
  sample_n(75, replace = FALSE)
muestra_b <- datos |> filter(estado == "A") |>
  sample_n(75, replace = FALSE)

i_train <- sample(1:75, 50)
entrenamiento <- rbind(muestra_a[i_train, ], muestra_b[i_train, ]) |> sample_frac(1L)
prueba <- rbind(muestra_a[-i_train, ], muestra_b[-i_train, ]) |> sample_frac(1L)
```

Una vez obtenido el conjunto de entrenamiento y de prueba. Se decide hacer una regresión logística múltiple, dado que la variable de respuesta será estado, podemos observar que es una variable dicotómica lo que la hace perfecta para este tipo de regresión.
Luego se debe usar usar RFE para conseguir un modelo de regresión logística múltiple (RLogitM), que incluya de 3 a 6 predictores, utilizando validación cruzada dejando uno fuera para evitar el sobreajuste.

```{r}
rlogitm_fmla <- formula(paste("estado", ".", sep = " ~ "))
rlogitm_df <- entrenamiento

lrFuncs[["summary"]] <- twoClassSummary
rlogitm_rfe_control <- rfeControl(functions = lrFuncs, method = "LOOCV", saveDetails = TRUE, returnResamp = "all", verbose = FALSE)
rlogitm_train_control <- trainControl(method = "none", classProbs = TRUE,
                                      summaryFunction = twoClassSummary)

set.seed(17 * 11111)
rlogitm_rfe <- suppressWarnings(
  rfe(rlogitm_fmla, data = rlogitm_df, sizes = 3:6, metric = "ROC",
      rfeControl = rlogitm_rfe_control, trControl = rlogitm_train_control)
)
rlogitm <- rlogitm_rfe[["fit"]]

cat("Modelo de RLogitM obtenido con RFE:\n")
print(summary(rlogitm))
```

Podemos ver el proceso de búsqueda realizado por RFE. Se obtiene el predictor beca, motivacion, autoestima e interpersonales.

```{r plot RFE RLogitM, fig.align='center', fig.width=6, fig.height=4}
rlogitm_rfe_p <- ggplot(rlogitm_rfe) + theme_pubr()
print(rlogitm_rfe_p)
```

Por lo que finalmente tenemos el modelo de regresión logística múltiple. Luego vamos a verificar multicolinealidad.

```{r}
cat("Factores de inflación de la varianza:\n")
print(vif(rlogitm))
cat("\n")
cat("Valores de tolerancia:\n")
print(1 / vif(rlogitm))
```

Todos los valores de VIF están por debajo de 2, lo que sugiere que la multicolinealidad no es un problema significativo. Además, valores de tolerancia están por encima de 0.1, lo que tampoco hay un problema significativo con estos predictores.

Luego se verifica sobre-influencia con el gráfico de influencia.

```{r}
rlogitm_inf_estad <- influencePlot(rlogitm, id = list(n = 3))

cat("Casos notorios para el modelo de RLogitM:\n")
print(rlogitm_inf_estad)
cat("\n")
cat("Rango para 95% de los residuos studentizados: ")
cat("[", round(qt(0.05/2, nrow(rlogitm_df) - length(predictors(rlogitm)) - 2), 3), ", ", sep = "")
cat(round(qt(1-0.05/2, nrow(rlogitm_df) - length(predictors(rlogitm)) - 2), 3), "]\n", sep = "")
cat("Límite del apalancamiento:", round(2 * mean(hatvalues(rlogitm)), 3), "\n")
cat("Límite de la distancia de Cook:", round(3 * mean(cooks.distance(rlogitm)), 3), "\n")
```
Con esto, podemos observar que no hay casos notorios que esté fuera de rango de los tres criterios anteriores.

Se procede a analizar la independencia de los residuos.

```{r}
print(durbinWatsonTest(rlogitm))
```
Vemos que no hay razones para rechazar la independencia de los residuos de este modelo.

Finalmente, evaluamos la calidad predictiva el modelo obtenido. Debido a la validación cruzada dejando a uno afuera, solo evalua una observación en cada iteración, lo que tiene una tabla de confusión en donde calcula las métricas de desempeño. Por lo que podemos conocer esto inmediatamente.

```{r}
print(rlogitm_rfe[["results"]])
```
Con esto, podemos observar que la curva ROC obtenida para 4 predictores que el que finalmente escogimos. Vemos que el modelo obtenido tiene un rendimiento relativamente bueno, con un área bajo la curva ROC de 0.8192.

# Conclusión 
El modelo de regresión logística múltiple obtenido con 4 predictores siendo beca, motivacion, autoestima e interpersonales verificando condiciones de multicolinealidad, sobreinfluencia e independencia, al obtener los resultados predictivos podemos observar que es bastante bueno. Por lo que concluimos que el modelo obtenido se puede generalizar que es posible predecir la sitación final de la asignatura con un AUC de 0.8192 = 81,92% que este es mayor que el 75% o más pedido en el enunciado.
